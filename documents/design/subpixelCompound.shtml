#define S_DOCUMENTATION
#define S_DOCUMENTATION_DEVELOPER
#define PAGE Documentation
#define SUBPAGE Developer
#define TITLE Subpixel Compounds

#include "header.shtml"

<p>
Author: <a href="mailto:eilemann@gmail.com">eilemann@gmail.com</a><br/>
State: Design
</p>

<h2>Overview</h2>
<p>
  This features adds support for a new type of decomposition and recomposition,
  whereby each contributing channel renders one or multiple subsamples for
  full-scene anti-aliasing (FSAA) or depth-of-field (DOF). 
</p>
<p>
  Applications might already do multi-pass software FSAA/DOF, either during
  rendering or when the application is idle. Equalizer does not yet have a
  notion of idle/non-idle rendering.
</p>

<h2>Design</h2>
<p>
  The application will do the adding of the frustum jitter, since it is the one
  which knows how many FSAA and/or DOF samples are desired. Therefore it needs
  to know in Channel::frameDraw which sample out of how many it should render.
</p>
<p>
  The default implementation of Channel::applyFrustum will use the subpixel
  sample description to compute an FSAA jitter using a pre-defined lookup
  table. It will add this jitter to the frustum supplied by getFrustum.
</p>
<p>
  Applications which have their own SWAA settings will use the subpixel sample
  description to calculate how many passes with which samples have to be
  rendered, e.g., if it desires to render 16 samples on a 4-time decomposition,
  the application will render 4 passes out of a 16-value jitter lookup table on
  each channel.
</p>
<p>
  It is the application's responsibility to provide a blended result of the
  sub-passes on each channel. This should not be an overhead, since the
  application could already compute the accumulation and averaging before.
</p>
<p>
  Compositing
</p>

<h2>API</h2>
<!-- /* --><pre>
  vmml::Vector2f Channel::getJitter() const;
  vmml::Vector2i Channel::getSubpixel() const;
</pre><!-- */ -->

<h2>File Format</h2>
<!-- /* --><pre>
    compound
    {
        subpixel [ index size ]
    }
</pre><!-- */ -->

<h2>Implementation</h2>
<!-- /* --><pre>
Modify eqPly to do idle SWAA:

  EqPly
    static const uint32_t sampleSize

  FrameData
    bool     _idleMode

  Config
  	uint32_t _nbFramesAA
  	
  Channel
    FBO*     _accumBuffer
    uint32_t _primeNumberTable
    uint32_t _jitterStep
    uint32_t _nbSteps

  Config::startFrame
    if view is idle
      idleMode = true
      nbFramesAA--;
    else
      idleMode = false
    commit frame data
    
  Config::handleEvent
  	get the event IDLE_AA
  	nbFramesAA = MAX( nbFramesAA, event->jitter )

  Channel::frameViewStart
    if view is not in idle mode
      jitter = nbSteps
      
  Channel::frameViewFinish
    frameAssemble is done and back buffer is ready
    if view is idle
      if jitter > 0
        if first idle step
          reset accum buffer
        accumulate back buffer to accum buffer
        compute average in back buffer
        jitter--
      else if jitter == 0
        put the accum buffer result in the back buffer
    send event to the config

  Channel::applyFrustum
    frustum = getFrustum()
    jitter = getJitter();
    frustum += jitter;
    glFrustum( ... );

  Channel::_lookupPrimeNumberTable( channel ID )

  Channel::_generateFloatRand( begin, end )

  Channel::_computeJitterStep
    subset_size = ( sample_size * sample_size ) / nb_channels
    idx =  ( idle_step * getPrimeNumber()) % subset_size
    global_jitter = ( id_channel * subset_size ) + idx

  Channel::_computeJitter
    Compute normalized jitter area (idle step, channel index)
    Compute pixel size on near plane (frustum)
    Compute random sample position in normalized coordinates
    jitter = jitter area * pixel size * random position
    Attn: Floating point rounding errors!

--------------------------------------------------
Current idle AA in Eq application:

  Channel::frameViewFinish()
    assemble input frames into back buffer
    if view is idle
      if first idle step
        reset accum buffer
      accumulate back buffer to accum buffer
      compute average in back buffer
    
      
  Channel::frameDraw()
    if view is idle
      get idle step # and jitter frustum
    render

Idle AA with AA compounds:
  Channel::frameAssemble()
    if input frames have more than one jitter step
      composite images using accumulation
      -> need to know jitter state of current framebuffer

    if( more than one jitter decomp [self+input frames] )
       assemble all input frames with self jitter decomp
       load accum buffer
       for each remaining jitter decomp
         assemble all input frames with jitter decomp
         add accum buffer
       return accum buffer
       

  Channel::frameViewFinish()
    if first idle step
      reset accum buffer
    if has more than one jitter step or view is idle
      for each jitter step in input frames
        assemble input frames with jitter step in back buffer
        accumulate back buffer in accum buffer
        ++n
      compute average in back buffer
      increase application idle steps done by n
      
  Channel::frameDraw()
    jitter step = f(application idle step, Channel jitter param)
      jitter step = idle_step * jitter_grp_size + jitter_offset
    render

--------------------------------------------------
 Add new subpixel parameter in loader
 Add new subpixel parameter in Compound::InheritData
 Update subpixel in Compound::updateInheritData
 Update subpixel in CompoundUpdateOutput::_updateOutput
 Set subpixel in ChannelUpdateVisitor::_setupRenderContext
 Create getter in eq::Channel
 Add subpixel to eq::FrameData (+ setter in the server FrameData)
 
 Use Channel::getSubpixel for rendering
   -> step & subpixel groups size?
 
 Compositor extension?
 frameAssemble and frameViewFinish logics?
</pre><!-- */ -->

<a name="Issues"></a>
<h2>Issues</h2>

<h3>1. Do we need a one-dimensional or two-dimensional subpixel description for
  each source channel?</h3>
<p>
  This depends on Q2. My feeling is a one-dimensional attribute is easier.
</p>

<h3>2. How do I compute my current jitter area?</h3>
<p>
  The number of jitter areas, i.e, the number of FSAA or DOF samples, is an
  application parameter. The current jitter area within each Channel::frameDraw
  is a function of the current idle step and the channel's subpixel description.
</p>
<p>
  Open Issue: the function itself. The jitter values for all channels in the
  first pass should be evenly distributed over the total subpixel grid.
</p>
<p>
  Idea: Divide the sample grid into the number of channels to get a subset of 
  pixels for each channel. 
  For each pass, compute (pass_number * rnd_prime_number) % size to get kind 
  of a randomized distribution. The size parameter is the size of the pixel 
  subset for the current channel.
</p>

<h3>3. How do I disable FSAA when it's not supported?</h3>
<p>
  Depending on the OpenGL version, we run either the glAccum method either the FBO'str one.
  On MacOSX, a different implementation of glAccum is needed.
</p>
<p>
  MacOSX problem: floating point texture not supported and the use of glAccum 
  needs a different implementation.
</p>

<h3>4. How do I compute the jitter steps for FSAA compound?</h3>
<p>
  The destination channel asks for a new frame instead that the config starts a 
  new frame itself. Each destination channel sends an event to the config which 
  takes the maximum number of steps needed and enables to start a new frame.
</p>

<h3>5. How do I decrement the jitter steps done in the current frame?</h3>
<p>
  The destination channel might render 0..n jitter steps and receive 0..n jitter
  steps as input frames during compositing.
</p>
<p>
  We could assume that a subpixel decomposition parameter is set for the
  destination channel. If the destination channel does a frameDraw, he will
  decrement the jitter step by the subpixel decomposition size in frameDraw,
  otherwise he will decrement it by the subpixel decomposition size of the input
  frames in frameAssemble:
</p>
<!-- /* --><pre>
  Channel::frameStart
    _subpixelSteps = 0;
  Channel::frameDraw
    _subpixelSteps = EQ_MAX( _subpixelSteps, subpixel.size );
  Channel::frameAssemble
    for each input frame
      _subpixelSteps = EQ_MAX( _subpixelSteps, frame.subpixel.size );
  Channel::frameFinish
    _jitterSteps -= _subpixelSteps;
    send event
</pre><!-- */ -->

<h3>5. How does the accumulation in frameAssemble work together with the one in
  frameViewFinish?</h3>
<p>
  Without any scalability, each destination channel accumulates in idle mode the
  results of different frames into an accumulation buffer. With scalability,
  frameAssemble might accumulate the results of different, jittered input
  frames.
</p>
<p>
  A simple, but non-optimal solution is to assemble and average all jitter steps
  in frameAssemble, and to transfer the result into the accumulation buffer n
  times in frameViewFinish:
</p>
<!-- /* --><pre>
  Channel::frameAssemble
    accumulate all input frames in separate accum buffer
    return accum buffer to frame buffer
  Channel::frameViewFinish
    copy frame buffer _subpixelSteps times into accum buffer
    _stepsDone += _subpixelSteps;
    return accum buffer
</pre><!-- */ -->
<p>
  In the optimal case, frameAssemble and frameViewFinish should share the
  accumulation buffer:
</p>
<!-- /* --><pre>
  Channel::frameDraw
    set _needsTransfer
  Channel::frameAssemble
    if( all input frames have Subpixel::ALL )
      do normal assembly
      set _needsTransfer
    else if for each jitter decomp in input frames
      assemble all input frames with jitter decomp
      accumulate result
      clear _needsTransfer
  Channel::frameViewFinish
    if _needsTransfer
      accumulate FB into accum buffer
    return accum buffer
</pre><!-- */ -->

#include "footer.shtml"
<!-- $Id$ -->
